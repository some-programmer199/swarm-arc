{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d58c28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "# Define transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with MNIST mean and std\n",
    "])\n",
    "# Create data loaders for batch processing\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',  # Where to store the dataset\n",
    "    train=True,     # This is training data\n",
    "    download=True,  # Download if not present\n",
    "    transform=transform  # Apply transformations\n",
    "code\n",
    "python\n",
    "# Comparison: baseline training vs genome-decoded weights\n",
    "import time\n",
    "import model\n",
    "from copy import deepcopy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# small eval helpers\n",
    "def evaluate(net, data_loader, device):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = net(x)\n",
    "            loss_sum += criterion(out, y).item()\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return {\"loss\": loss_sum/total, \"acc\": correct/total}\n",
    "\n",
    "# Quick baseline: train for a few mini-epochs (keeps runtime small)\n",
    "def quick_train(net, train_loader, device, steps=200, lr=0.01):\n",
    "    net.to(device)\n",
    "    opt = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    net.train()\n",
    "    it = iter(train_loader)\n",
    "    for i in range(steps):\n",
    "        try:\n",
    "            x, y = next(it)\n",
    "        except StopIteration:\n",
    "            it = iter(train_loader)\n",
    "            x, y = next(it)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = net(x)\n",
    "        loss = crit(out, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return net\n",
    "\n",
    "# Build baseline model and run quick training\n",
    "baseline = SimpleNN()\n",
    "start = time.time()\n",
    "baseline = quick_train(baseline, train_loader, device, steps=200, lr=0.01)\n",
    "baseline_time = time.time() - start\n",
    "baseline_stats = evaluate(baseline, test_loader, device)\n",
    "print(\"Baseline quick-train time: %.2fs\" % baseline_time)\n",
    "print(\"Baseline test loss=%.4f acc=%.4f\" % (baseline_stats['loss'], baseline_stats['acc']))\n",
    "\n",
    "# Now compare to genome-decoded weight initializations (random genomes)\n",
    "decoder = model.GenomeDecoder(genome_dim=128, hidden=256, out_dim=256)\n",
    "num_trials = 8\n",
    "genome_dim = 128\n",
    "results = []\n",
    "for t in range(num_trials):\n",
    "    net = SimpleNN()\n",
    "    # random genome per trial\n",
    "    genome = torch.randn(genome_dim) * 0.1\n",
    "    # fill params with decoder-generated values\n",
    "    try:\n",
    "        model.fill_params(net, genome, decoder)\n",
    "    except Exception as e:\n",
    "        print(\"fill_params failed:\", e)\n",
    "        continue\n",
    "    net.to(device)\n",
    "    stats = evaluate(net, test_loader, device)\n",
    "    print(f\"Trial {t+1}/{num_trials}: loss={stats['loss']:.4f} acc={stats['acc']:.4f}\")\n",
    "    results.append((stats['loss'], stats['acc']))\n",
    "\n",
    "# Summarize\n",
    "if results:\n",
    "    losses, accs = zip(*results)\n",
    "5\n",
    "4\n",
    ",\n",
    "\n",
    "    print(\"  loss: mean=%.4f std=%.4f\" % (np.mean(losses), np.std(losses)))\n",
    "    print(\"  acc : mean=%.4f std=%.4f\" % (np.mean(accs), np.std(accs)))\n",
    "    print(\"Baseline acc=%.4f Loss=%.4f\" % (baseline_stats['acc'], baseline_stats['loss']))\n",
    "else:\n",
    "    print(\"No genome trials completed successfully\")\n",
    "            running_loss = 0.0\n",
    "# Suggest next steps\n",
    "print(\"\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(10):\n",
    "        axes[i].imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "        axes[i].set_title(f\"Label: {labels[i]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()plt.grid(True)plt.ylabel('Loss')plt.xlabel('Training Steps (x100)')plt.title('Training Loss')plt.plot(train_losses)plt.figure(figsize=(10, 5))print('Training finished!')            running_loss = 0.0            train_losses.append(running_loss/100)            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')        if (i+1) % 100 == 0:        running_loss += loss.item()        # Print statistics        optimizer.step()        loss.backward()        # Backward pass and optimize        loss = criterion(outputs, labels)        outputs = model(inputs)        # Forward pass        optimizer.zero_grad()        # Zero the parameter gradients        inputs, labels = inputs.to(device), labels.to(device)        # Move tensors to the configured devicefor i, (inputs, labels) in enumerate(train_loader):    running_loss = 0.0for epoch in range(num_epochs):train_losses = []num_epochs = 5# Training loopmodel.to(device)print(f\"Using device: {device}\")device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")# Check if GPU is availableoptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)criterion = nn.CrossEntropyLoss()print(model)model = SimpleNN()# Initialize the model        return x        x = self.fc3(x)        x = self.relu(x)        x = self.fc2(x)        x = self.relu(x)        x = self.fc1(x)        x = self.flatten(x)    def forward(self, x):        self.fc3 = nn.Linear(64, 10)        self.fc2 = nn.Linear(128, 64)        self.relu = nn.ReLU()        self.fc1 = nn.Linear(28*28, 128)        self.flatten = nn.Flatten()        super(SimpleNN, self).__init__()    def __init__(self):class SimpleNN(nn.Module):test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)# Create data loaders for batch processingshow_images(images[:10], labels[:10])# Show imagesimages, labels = next(dataiter)dataiter = iter(train_loader)# Get some random training imagestest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)    plt.show()    plt.tight_layout()        axes[i].axis('off')plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae15dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import model\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
